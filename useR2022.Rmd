---
title: "Power Under Multiplicity"
subtitle: ""
author: ""
institute: ""
date: ""
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    seal: false
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

class: center, inverse

<br><br>

<h1 style="font-size:3.5rem;"> Power Under Multiplicity </h1>

<br>

<h2 style="font-size:1.75rem;">Kristen Hunter,<sup>1*</sup> Luke Miratrix,<sup>1,2</sup> Kristin Porter<sup>3</sup> </h2>

<h3 style="font-size:1.5rem;">useR! 2022 </h3>

Slides available: github.com/MDRCNY/PUMP

<br>

<p style="text-align:left;font-size:0.75rem">
*Contact: kristenbhunter@gmail.com <br>
[1] Harvard Department of Statistics<br>
[2] Harvard Graduate School of Education <br>
[3] MDRC 
</p>


```{r initialize, include = FALSE}
library( knitr )
library( tidyverse )
library( PUMP )

set.seed(0905)

knitr::opts_chunk$set(
  cache = TRUE,
  warning = FALSE,
  message = FALSE
)

library( wesanderson )
plot.colors = wes_palette('Darjeeling1', n = 4)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library( xaringan )
library( xaringanthemer )
style_mono_accent(
  base_color = "#43418A",
  code_highlight_color = "#000",
)
```

```{css, echo = FALSE}
ul {
  line-height: 1.5;
}
```

---

# Multiple outcomes

- With **multiple outcomes** in a study, must use a multiple testing procedure (MTP) to obtain valid conclusions.
- The use of MTPs changes statistical **power**.

<p style="float: left; font-size: 5pt; text-align: center; width: 30%; margin-right: 1%; margin-bottom: 2em"><img src="figures/agility1.jpg" style="width: 100%; height: 300px">Image by <a href="https://pixabay.com/users/yamabsm-1300729/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3120383">Yama Zsuzsanna MÃ¡rkus</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3120383">Pixabay</a></p>
<p style="float: left; font-size: 5pt; text-align: center; width: 30%; margin-right: 1%; margin-bottom: 0.5em;"><img src="figures/agility2.jpg" style="width: 100%; height: 300px">Image by <a href="https://pixabay.com/users/825545-825545/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=748260">Katrin B.</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=748260">Pixabay</a></p>
<p style="float: left; font-size: 5pt; text-align: center; width: 30%; margin-right: 1%; margin-bottom: 0.5em;"><img src="figures/agility3.jpg" style="width: 100%; height: 300px">Image by <a href="https://pixabay.com/users/825545-825545/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=747770">Katrin B.</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=747770">Pixabay</a></p>
<p style="clear: both;">

---

# Motivation

.pull-left[
Problem:
- Current practice for determining statistical power does not take the use of MTPs into account.

<p style="float: left; font-size: 5pt; text-align: center; width: 100%; margin-right: 1%; margin-bottom: 2em"><img src="figures/pump.jpg" style="width: 100%; height: 200px"><br>Image by <a href="https://pixabay.com/users/947051-947051/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1008977">Jan Steiner</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1008977">Pixabay</a></p>

]

.pull-right[
Solution:
- Introducing **PUMP**.
- R package.
- Power Under Multiplicity Project.
- Calculates power for multiple hypotheses in multilevel randomized controlled trial (RCT) designs.

<br>

- Multilevel: hierarchical structure, such as students nested within schools nested within districts
- Assumes analyst will use frequentist mixed effects models
- Running example: education experiments

]




---

# Example

```{r, echo = FALSE}
pow <- pump_power(
  d_m =  "d2.1_m2fc",    # choice of design and model
  MTP = "BF",            # multiple testing procedure
  MDES = rep( 0.10, 3 ), # assumed effect size
  M = 3,                 # number of outcomes
  J = 10,                # number of schools/blocks
  nbar = 275,            # average number of students per school
  Tbar = 0.50,           # proportion of students treated per school
  alpha = 0.05,          # significance level
  numCovar.1 = 5,        # number of covariates at level 1
  R2.1 = 0.1,            # assumed R^2 of level 1 covariates
  ICC.2 = 0.05,          # intraclass correlation
  rho = 0.4              # test statistic correlation
) 
```

I have 3 outcomes, with a 2-level blocked design.
My power to detect the effect for any individual outcome:
- Without any adjustment (no MTP): `r round(pow$D1indiv[1], 2)`.
- Using Bonferroni adjustment: `r round(pow$D1indiv[2], 2)`.

Having multiple outcomes has reduced my power...or has it? Stay tuned!

<p style="float: left; font-size: 5pt; text-align: center; width: 45%; margin-right: 1%; margin-bottom: 2em"><img src="figures/flyingdog.jpg" style="width: 100%; height: 250px">Image by <a href="https://pixabay.com/users/brian_cragun-19680916/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5946987">Brian Cragun</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5946987">Pixabay</a></p>
<p style="float: left; font-size: 5pt; text-align: center; width: 45%; margin-right: 1%; margin-bottom: 0.5em;"><img src="figures/smalldog.jpg" style="width: 60%; height: 250px; align="middle"><br>Photo by <a href="https://unsplash.com/@just_another_photographa?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">James Watson</a> on <a href="https://unsplash.com/s/photos/funny-dog?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a></p>


---

# Factors affecting power

With at least one outcome:

- design of the study and assumed model
- $\bar{n}$, $J$, $K$: number of level 1/2/3 units
- $\bar{T}$: proportion of students treated
- number of covariates, $R^2$: explanatory power of covariates
- $ICC$: intraclass correlation (ratio of variance at a particular level to overall variance)


Unique to **multiple** outcomes:

- definition of power
- $M$: number of outcomes/tests
- $\rho$: correlation between test statistics
- proportion of outcomes for which there are truly effects
- multiple testing procedure (MTP)
  
---

# Define the setup

.pull-left[
How to **design** the experiment
- Levels: 1, 2, 3
- Randomization level: 1, 2, 3

How to **model** the experiment
- Assumes mixed effects regression models
- Intercepts: fixed or random
- Treatment effects: constant, fixed, or random
]

.pull-right[
Supported designs and models:
- d1.1_m1c
- d2.1_m2fc
- d2.1_m2ff
- d2.1_m2fr
- d2.1_m2rr
- d2.2_m2rc
- d3.1_m3rr2rr
- d3.2_m3fc2rc
- d3.2_m3ff2rc
- d3.2_m3rr2rc
- d3.3_m3rc2rc
]

---

# Definitions of power

How do we define power if we have *multiple* hypotheses/outcomes?
- **Individual** power: probability of rejecting a particular null hypothesis
- **1-Minimal** power: probability of rejecting at least one null hypothesis
- **D-Minimal** power: probability of rejecting at least d null hypotheses
- **Complete** power: probability of rejecting all the null hypotheses

All valid options--the choice depends on how we want to define success!


<p style="float: left; font-size: 5pt; text-align: center; width: 45%; margin-right: 1%; margin-bottom: 2em"><img src="figures/pug.jpg" style="width: 80%; height: 200px"><br>Image by <a href="https://pixabay.com/users/woodsilver-4045569/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2105686">woodsilver</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2105686">Pixabay</a></p>
<p style="float: left; font-size: 5pt; text-align: center; width: 45%; margin-right: 1%; margin-bottom: 0.5em;"><img src="figures/bigjump.jpg" style="width: 80%; height: 200px; align="middle"><br>Image by <a href="https://pixabay.com/users/snottyboggins-6421955/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4048815">SnottyBoggins</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4048815">Pixabay</a></p>

---
# Multiple testing procedures

- **Bonferroni**
  - simple
  - most conservative
- **Holm**
  - step down version of Bonferroni
  - less conservative for larger $p$-values than Bonferroni
- **Benjamini-Hochberg** 
  - step up procedure
  - controls the false discovery rate (less conservative)
- **Westfall-Young** (single step and step down versions)
  - permutation-based approach
  - takes into account correlation structure of outcomes
  - computationally intensive
  - not overly conservative
---

# Diving in!

```{r}
library( PUMP )

pow <- pump_power(
  d_m =  "d2.1_m2fc",    # choice of design and model
  MTP = "BF",            # multiple testing procedure
  MDES = rep( 0.10, 3 ), # assumed effect size
  M = 3,                 # number of outcomes
  J = 10,                # number of schools/blocks
  nbar = 275,            # average number of students per school
  Tbar = 0.50,           # proportion of students treated per school
  alpha = 0.05,          # significance level
  numCovar.1 = 5,        # number of covariates at level 1
  R2.1 = 0.1,            # assumed R^2 of level 1 covariates
  ICC.2 = 0.05,          # intraclass correlation
  rho = 0.4              # test statistic correlation
) 
```

---

# Power results

```{r, echo = FALSE}
kable(pow, digits = 2)
```

Takeaways
- Individual power using Bonferroni is lower
- Min1 power is higher than individual power
- Complete power is lowest

---

# How it works

- For simple designs and one outcome, we often have a formula for power
- It would be difficult (in some cases impossible) to derive explicit formulas for every design, model, number of outcomes, MTP, and definition of power

<br><br>

Instead, we use **simulation**! A full simulation approach would be:

1. *Simulate data* according to the alternative hypotheses.
2. *Calculate test statistics* under the alternative hypotheses.
3. Use these test statistics to calculate $p$-values.
4. Calculate power using the distribution of $p$-values.

---

# How it works

- We can simplify this approach by skipping step 1.
- Given:
  - design and model
  - correlation between test statistics for different hypotheses
- We know the joint alternative distribution of test statistics!
- Results in **simpler** and **faster** power calculations.

<br>

Simulation approach to calculating power:
1. *Sample test statistics* under the alternative hypotheses.
2. Use these test statistics to calculate $p$-values.
3. Calculate power using the distribution of $p$-values.

<br>
Note: because we use simulations to calculate power, estimates are approximate, but the user can increase the number of test statistic draws to increase precision.

---

# Sample size and MDES

We can also calculate:
- `pump_mdes()`: minimum detectable effect size (MDES) for a particular target power
- `pump_sample()`: sample size for a given target power and MDES

Types of sample size calculations:
- K: number of level 3 units (districts)
- J: number of level 2 units (schools)
- nbar: number of level 1 units (students)

---

# Sample size example

```{r}
ss <- pump_sample(
  target.power = 0.8,        # target power
  power.definition = "min1", # power definition
  typesample = "J",          # type of sample size procedure
  tol = 0.01,                # tolerance
  d_m =  "d2.1_m2fc", MTP = "BF",
  MDES = 0.1, M = 3, nbar = 350, Tbar = 0.50, alpha = 0.05,
  numCovar.1 = 5, R2.1 = 0.1, ICC.2 = 0.05, rho = 0.4
)
```

<br>

```{r, echo = FALSE}
ss <- data.frame(
  'MTP' = 'BF',
  'Sample type' = 'J',
  'Sample size' = 7,
  'min1 power' = 0.80625)
kable(ss, digits = 2)
```
  
---

# Assessing sensitivity

We can use the grid function to assess sensitivity to different model and design parameters.

```{r, cache = TRUE, echo = TRUE}
pgrid <- update_grid(
  pow,
  # vary parameter values
  rho = seq( 0, 0.9, by = 0.1 ), 
  # compare multiple MTPs
  MTP = c( "BF", "HO", "WY-SS", "BH" )
)
```
---

# Assessing sensitivity

```{r echo = TRUE, fig.width = 10, fig.height = 6}
plot( pgrid, var.vary = 'rho' )
```

---

class: inverse

# Summary: PUMP

- Estimates power for multiple outcomes for multilevel RCTs
- Takes into account multiple testing procedures
- Calculates minimum detectable effect size (MDES) and sample size
- Allows user to assess sensitivity of power to different parameters

---

class: inverse

# Available now!



- CRAN: [CRAN.R-project.org/package=PUMP](https://cran.r-project.org/web/packages/PUMP/index.html)
- Shiny app: [mdrc.shinyapps.io/pump](https://mdrc.shinyapps.io/pump/)
- Github: [github.com/MDRCNY/PUMP](https://github.com/MDRCNY/PUMP)
- arXiv: [arxiv.org/abs/2112.15273](https://arxiv.org/abs/2112.15273)
- Contact: kristenbhunter@gmail.com

<p style="float: left; font-size: 5pt; text-align: center; width: 100%; margin-right: 1%; margin-bottom: 0.5em;"><img src="figures/wasabi.jpg" style="width: 60%; height: 300px; align="middle"><br>Image by NYTimes</p>




